#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Fixed MCP Agent Demo - Resolves API compatibility issues

This script provides a working demonstration of the MCP Agent with proper
error handling and API compatibility fixes.

Usage:
    python examples/fixed_mcp_demo.py

Author: DataMax Team
Date: 2024
License: MIT
"""

import asyncio
import os
import json
from typing import Dict, Any
from datamax.generator.mcp_agent_generator import (
    MCPAgent,
    MCPAgentConfig,
    ToolDefinition,
    ToolType,
    MessageRole
)


class FixedMCPAgent(MCPAgent):
    """Fixed MCP Agent with improved API compatibility"""
    
    def _prepare_messages_for_llm(self):
        """Prepare messages with better API compatibility"""
        messages = []
        
        # Add system message
        system_prompt = f"""
You are {self.config.name}, an advanced AI assistant powered by the DataMax framework.

You have access to the following tools:
{json.dumps([{"name": tool.name, "description": tool.description} for tool in self.tools.values()], indent=2)}

You can call these tools to help users with various tasks including data processing, file operations, and web searches.
Always be helpful, accurate, and provide detailed explanations of your actions.

Session ID: {self.session_id}
"""
        
        messages.append({"role": "system", "content": system_prompt})
        
        # Add conversation history with careful filtering
        i = 0
        while i < len(self.conversation_history):
            msg = self.conversation_history[i]
            
            if msg.role == MessageRole.SYSTEM:
                i += 1
                continue
            
            if msg.role == MessageRole.USER:
                messages.append({
                    "role": "user",
                    "content": msg.content
                })
            elif msg.role == MessageRole.ASSISTANT:
                # Check if this assistant message has tool calls
                if msg.metadata and "tool_calls" in msg.metadata:
                    # This is an assistant message with tool calls
                    messages.append({
                        "role": "assistant",
                        "content": msg.content,
                        "tool_calls": msg.metadata["tool_calls"]
                    })
                    
                    # Look for corresponding tool messages
                    j = i + 1
                    while j < len(self.conversation_history) and self.conversation_history[j].role == MessageRole.TOOL:
                        tool_msg = self.conversation_history[j]
                        if tool_msg.metadata and "tool_call_id" in tool_msg.metadata:
                            messages.append({
                                "role": "tool",
                                "content": tool_msg.content,
                                "tool_call_id": tool_msg.metadata["tool_call_id"]
                            })
                        j += 1
                    i = j - 1  # Skip the tool messages we just processed
                else:
                    # Regular assistant message
                    messages.append({
                        "role": "assistant",
                        "content": msg.content
                    })
            
            i += 1
        
        return messages
    
    async def process_message(self, user_message: str):
        """Process message with improved error handling"""
        try:
            # Add user message to history
            self.add_message(MessageRole.USER, user_message)
            
            # Prepare messages and tools for LLM
            messages = self._prepare_messages_for_llm()
            tools = self._prepare_tools_for_llm()
            
            # Call LLM with or without tools
            response_kwargs = {
                "model": self.config.model_name,
                "messages": messages,
                "temperature": self.config.temperature,
                "max_tokens": self.config.max_tokens
            }
            
            # Only add tools if they exist and tool calling is enabled
            if tools and self.config.enable_tool_calling:
                response_kwargs["tools"] = tools
                response_kwargs["tool_choice"] = "auto"
            
            response = self.llm_client.chat.completions.create(**response_kwargs)
            assistant_message = response.choices[0].message
            
            # Handle tool calls if present
            if hasattr(assistant_message, 'tool_calls') and assistant_message.tool_calls:
                return await self._handle_tool_calls(assistant_message)
            else:
                # No tool calls, just add the assistant response
                return self.add_message(MessageRole.ASSISTANT, assistant_message.content or "I understand your request.")
        
        except Exception as e:
            logger.error(f"Error processing message: {e}")
            error_response = f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶é‡åˆ°äº†é”™è¯¯ã€‚è®©æˆ‘ç”¨å…¶ä»–æ–¹å¼æ¥å¸®åŠ©æ‚¨ã€‚"
            return self.add_message(MessageRole.ASSISTANT, error_response)
    
    async def _handle_tool_calls(self, assistant_message):
        """Handle tool calls separately for better error control"""
        try:
            # Convert tool calls to serializable format
            tool_calls_data = []
            for tc in assistant_message.tool_calls:
                tool_calls_data.append({
                    "id": tc.id,
                    "type": "function",
                    "function": {
                        "name": tc.function.name,
                        "arguments": tc.function.arguments
                    }
                })
            
            # Add assistant message with tool calls
            self.add_message(
                MessageRole.ASSISTANT,
                assistant_message.content or "æˆ‘æ¥ä½¿ç”¨å·¥å…·å¸®åŠ©æ‚¨å¤„ç†è¿™ä¸ªè¯·æ±‚ã€‚",
                metadata={"tool_calls": tool_calls_data}
            )
            
            # Execute tool calls
            for tool_call in assistant_message.tool_calls:
                tool_name = tool_call.function.name
                try:
                    tool_args = json.loads(tool_call.function.arguments)
                    
                    if tool_name in self.tools:
                        tool_impl = self.tools[tool_name].implementation
                        if tool_impl:
                            result = tool_impl(**tool_args)
                            
                            # Add tool result message
                            self.add_message(
                                MessageRole.TOOL,
                                json.dumps(result, ensure_ascii=False),
                                metadata={"tool_call_id": tool_call.id, "tool_name": tool_name}
                            )
                except Exception as tool_error:
                    logger.error(f"Tool execution error: {tool_error}")
                    # Add error result
                    error_result = {"success": False, "error": f"å·¥å…·æ‰§è¡Œé”™è¯¯: {str(tool_error)}"}
                    self.add_message(
                        MessageRole.TOOL,
                        json.dumps(error_result, ensure_ascii=False),
                        metadata={"tool_call_id": tool_call.id, "tool_name": tool_name}
                    )
            
            # Get final response after tool execution
            final_messages = self._prepare_messages_for_llm()
            final_response = self.llm_client.chat.completions.create(
                model=self.config.model_name,
                messages=final_messages,
                temperature=self.config.temperature,
                max_tokens=self.config.max_tokens
            )
            
            final_content = final_response.choices[0].message.content
            return self.add_message(MessageRole.ASSISTANT, final_content or "ä»»åŠ¡å·²å®Œæˆã€‚")
            
        except Exception as e:
            logger.error(f"Tool call handling error: {e}")
            error_response = "æˆ‘åœ¨ä½¿ç”¨å·¥å…·æ—¶é‡åˆ°äº†ä¸€äº›é—®é¢˜ï¼Œä½†æˆ‘ä»ç„¶å¯ä»¥ä¸ºæ‚¨æä¾›å¸®åŠ©ã€‚è¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆã€‚"
            return self.add_message(MessageRole.ASSISTANT, error_response)


def create_fixed_agent() -> FixedMCPAgent:
    """Create a fixed MCP agent with better configuration"""
    # Try different API configurations
    api_key = os.getenv("OPENAI_API_KEY") or os.getenv("DASHSCOPE_API_KEY")
    
    if not api_key:
        raise ValueError("è¯·è®¾ç½® OPENAI_API_KEY æˆ– DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡")
    
    if os.getenv("OPENAI_API_KEY"):
        config = MCPAgentConfig(
            name="Fixed-OpenAI-Agent",
            api_key=os.getenv("OPENAI_API_KEY"),
            base_url="https://api.openai.com/v1",
            model_name="gpt-3.5-turbo",
            temperature=0.7,
            enable_tool_calling=True,
            enable_memory=True,
            log_level="WARNING"
        )
    else:
        config = MCPAgentConfig(
            name="Fixed-DashScope-Agent",
            llm_provider="dashscope",
            api_key=os.getenv("DASHSCOPE_API_KEY"),
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
            model_name="qwen-turbo",
            temperature=0.7,
            enable_tool_calling=False,  # Disable tool calling for DashScope to avoid issues
            enable_memory=True,
            log_level="WARNING"
        )
    
    return FixedMCPAgent(config)


def add_sample_data_tool(agent: FixedMCPAgent):
    """Add a sample data generation tool"""
    def generate_sales_data(record_count: int = 10, region: str = "å…¨å›½") -> Dict[str, Any]:
        """Generate sample sales data"""
        import random
        from datetime import datetime, timedelta
        
        try:
            sales_data = []
            products = ["äº§å“A", "äº§å“B", "äº§å“C", "äº§å“D", "äº§å“E"]
            regions = ["åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·"] if region == "å…¨å›½" else [region]
            
            for i in range(record_count):
                record = {
                    "è®¢å•ID": f"ORD{1000 + i}",
                    "äº§å“åç§°": random.choice(products),
                    "é”€å”®æ•°é‡": random.randint(1, 100),
                    "å•ä»·": round(random.uniform(10, 1000), 2),
                    "é”€å”®åŒºåŸŸ": random.choice(regions),
                    "é”€å”®æ—¥æœŸ": (datetime.now() - timedelta(days=random.randint(0, 365))).strftime("%Y-%m-%d"),
                    "é”€å”®å‘˜": f"å‘˜å·¥{random.randint(1, 20)}"
                }
                record["æ€»é‡‘é¢"] = round(record["é”€å”®æ•°é‡"] * record["å•ä»·"], 2)
                sales_data.append(record)
            
            # Calculate summary
            total_amount = sum(record["æ€»é‡‘é¢"] for record in sales_data)
            total_quantity = sum(record["é”€å”®æ•°é‡"] for record in sales_data)
            
            return {
                "success": True,
                "data": sales_data,
                "summary": {
                    "è®°å½•æ•°": len(sales_data),
                    "æ€»é”€å”®é¢": round(total_amount, 2),
                    "æ€»é”€å”®æ•°é‡": total_quantity,
                    "å¹³å‡è®¢å•é‡‘é¢": round(total_amount / len(sales_data), 2),
                    "é”€å”®åŒºåŸŸ": region
                }
            }
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    # Register the tool
    sales_tool = ToolDefinition(
        name="generate_sales_data",
        description="ç”Ÿæˆç¤ºä¾‹é”€å”®æ•°æ®è®°å½•",
        type=ToolType.FUNCTION,
        parameters={
            "type": "object",
            "properties": {
                "record_count": {
                    "type": "integer",
                    "description": "è¦ç”Ÿæˆçš„è®°å½•æ•°é‡",
                    "default": 10,
                    "minimum": 1,
                    "maximum": 100
                },
                "region": {
                    "type": "string",
                    "description": "é”€å”®åŒºåŸŸ",
                    "default": "å…¨å›½",
                    "enum": ["å…¨å›½", "åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·"]
                }
            }
        },
        required=[],
        implementation=generate_sales_data
    )
    
    agent.register_tool(sales_tool)


async def demo_conversation():
    """Run a demonstration conversation"""
    print("ğŸš€ Fixed MCP Agent Demo")
    print("=" * 50)
    
    try:
        # Create agent
        agent = create_fixed_agent()
        
        # Add custom tools
        add_sample_data_tool(agent)
        
        print(f"âœ… Agent created: {agent.config.name}")
        print(f"ğŸ“Š Available tools: {list(agent.tools.keys())}")
        
        # Demo conversations
        demo_messages = [
            "ä½ å¥½ï¼ä½ èƒ½å¸®æˆ‘ç”Ÿæˆä¸€äº›é”€å”®æ•°æ®å—ï¼Ÿ",
            "è¯·ç”Ÿæˆ10æ¡åŒ—äº¬åœ°åŒºçš„é”€å”®è®°å½•",
            "èƒ½åˆ†æä¸€ä¸‹è¿™äº›æ•°æ®çš„ç‰¹ç‚¹å—ï¼Ÿ"
        ]
        
        for i, message in enumerate(demo_messages, 1):
            print(f"\nğŸ‘¤ User {i}: {message}")
            response = await agent.process_message(message)
            print(f"ğŸ¤– Agent: {response.content}")
            print("-" * 30)
        
        # Show conversation summary
        print("\nğŸ“Š Conversation Summary:")
        summary = agent.get_conversation_summary()
        for key, value in summary.items():
            print(f"  {key}: {value}")
        
        return agent
        
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        print("\nğŸ’¡ è¯·ç¡®ä¿:")
        print("1. è®¾ç½®äº†æ­£ç¡®çš„APIå¯†é’¥")
        print("2. ç½‘ç»œè¿æ¥æ­£å¸¸")
        print("3. APIé…é¢å……è¶³")
        return None


async def interactive_chat():
    """Interactive chat mode"""
    print("\nğŸ’¬ Interactive Chat Mode")
    print("è¾“å…¥ 'quit' æˆ– 'exit' ç»“æŸå¯¹è¯\n")
    
    try:
        agent = create_fixed_agent()
        add_sample_data_tool(agent)
        
        print(f"ğŸ¤– {agent.config.name} å·²å‡†å¤‡å°±ç»ªï¼")
        print(f"ğŸ“Š å¯ç”¨å·¥å…·: {', '.join(agent.tools.keys())}\n")
        
        while True:
            try:
                user_input = input("ğŸ‘¤ You: ").strip()
                
                if user_input.lower() in ['quit', 'exit', 'bye', 'é€€å‡º', 'å†è§']:
                    print("ğŸ¤– Agent: å†è§ï¼æ„Ÿè°¢ä½¿ç”¨ DataMax MCP Agentï¼")
                    break
                
                if not user_input:
                    continue
                
                print("ğŸ¤– Agent: ", end="", flush=True)
                response = await agent.process_message(user_input)
                print(response.content)
                print()
                
            except KeyboardInterrupt:
                print("\n\nğŸ‘‹ å†è§ï¼")
                break
            except Exception as e:
                print(f"\nâŒ é”™è¯¯: {e}")
                print("è¯·é‡è¯•ã€‚\n")
                
    except Exception as e:
        print(f"âŒ æ— æ³•å¯åŠ¨èŠå¤©: {e}")
        print("è¯·æ£€æŸ¥APIé…ç½®ã€‚")


async def main():
    """Main function"""
    print("ğŸ”§ DataMax MCP Agent - Fixed Demo")
    print("=" * 50)
    print("è¿™ä¸ªæ¼”ç¤ºè§£å†³äº†APIå…¼å®¹æ€§é—®é¢˜ï¼Œæä¾›æ›´ç¨³å®šçš„ä½“éªŒã€‚\n")
    
    # Check API keys
    if not (os.getenv("OPENAI_API_KEY") or os.getenv("DASHSCOPE_API_KEY")):
        print("âš ï¸  æœªæ‰¾åˆ°APIå¯†é’¥")
        print("è¯·è®¾ç½®ä»¥ä¸‹ç¯å¢ƒå˜é‡ä¹‹ä¸€:")
        print("  export OPENAI_API_KEY='your-openai-key'")
        print("  export DASHSCOPE_API_KEY='your-dashscope-key'")
        return
    
    print("ğŸ® é€‰æ‹©æ¨¡å¼:")
    print("1. æ¼”ç¤ºå¯¹è¯")
    print("2. äº¤äº’èŠå¤©")
    print("0. é€€å‡º")
    
    while True:
        try:
            choice = input("\nè¯·é€‰æ‹© (0-2): ").strip()
            
            if choice == "0":
                print("\nğŸ‘‹ å†è§ï¼")
                break
            elif choice == "1":
                await demo_conversation()
            elif choice == "2":
                await interactive_chat()
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡è¯•ã€‚")
                
        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ å†è§ï¼")